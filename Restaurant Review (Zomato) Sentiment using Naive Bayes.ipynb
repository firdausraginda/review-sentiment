{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './zomato.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    sentence = sentence.replace('\\ufeff','')\n",
    "    sentence = sentence.replace('\\n',' ')\n",
    "    sentence = sentence.replace('\\r',' ')\n",
    "    sentence = sentence.replace('\\n\\n',' ')\n",
    "    sentence = sentence.replace('\\r\\r',' ')\n",
    "    sentence = sentence.replace('.',' ')\n",
    "    sentence = sentence.replace(',',' ')\n",
    "    sentence = sentence.replace('\"',' ')\n",
    "    sentence = sentence.replace('!',' ')\n",
    "    sentence = sentence.replace('?',' ')\n",
    "    sentence = sentence.replace('/',' ')\n",
    "    sentence = sentence.replace('-',' ')\n",
    "    sentence = sentence.lstrip()\n",
    "    return sentence.lower()\n",
    "\n",
    "\n",
    "def count_word_in_class(x,y):\n",
    "    count = {}\n",
    "    count_word = {}\n",
    "    word_class = {}\n",
    "    for i in range(0, len(x)):\n",
    "        x_split = x[i].split()\n",
    "        for word in x_split:\n",
    "            w_c = word+str(\",\")+str(y[i])\n",
    "            if (w_c in count):\n",
    "                count[w_c] += 1\n",
    "            else:\n",
    "                count[w_c] = 1\n",
    "                \n",
    "            if (word in count_word):\n",
    "                count_word[word] += 1\n",
    "            else:\n",
    "                count_word[word] = 1\n",
    "                \n",
    "            if (y[i] in word_class):\n",
    "                word_class[y[i]] += 1\n",
    "            else:\n",
    "                word_class[y[i]] = 1\n",
    "    return count, count_word, word_class\n",
    "\n",
    "def count_class_in_doc(y):\n",
    "    count = {}\n",
    "    for i in range(0, len(y)):\n",
    "        if (y[i] in count):\n",
    "            count[y[i]] += 1\n",
    "        else:\n",
    "            count[y[i]] = 1\n",
    "    return count\n",
    "\n",
    "def hitung_prob(count,word,uniq):\n",
    "    return ((count + 1)/(word+uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "with open(path) as a:\n",
    "    b = csv.reader(a)\n",
    "    for row in b:\n",
    "        x.append(cleaning(row[2]))\n",
    "        y.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomize = np.arange(len(x))\n",
    "np.random.shuffle(randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x[:85]\n",
    "y_train = y[:85]\n",
    "\n",
    "x_test = x[85:]\n",
    "y_test = y[85:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_word_on_class, count_word, word_class = count_word_in_class(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_class = count_class_in_doc(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kelaz = list(count_class.keys())\n",
    "y_pred = []\n",
    "for i in range(0,len(x_test)):\n",
    "    prob_kelas = {}\n",
    "    for j in count_class.keys():\n",
    "        prob_c = 1\n",
    "        x_split = x_test[i].split()\n",
    "        for k in x_split:\n",
    "            tag = k+str(',')+str(j)\n",
    "            prob_c += math.log(hitung_prob(count_word_on_class.get(tag,0),word_class.get(j),len(count_word.keys())))\n",
    "        nama = str(i)+','+str(j)\n",
    "        prob_kelas[nama] = prob_c\n",
    "    y_pred.append(kelaz[np.argmax(list(prob_kelas.values()))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coba KFold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Acc of 6 Fold: 0.7212009803921569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "with open(path) as a:\n",
    "    b = csv.reader(a)\n",
    "    for row in b:\n",
    "        x.append(cleaning(row[2]))\n",
    "        y.append(row[3])\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "        \n",
    "randomize = np.arange(len(x))\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "acc = []\n",
    "folds = 6\n",
    "kf = KFold(n_splits=folds)\n",
    "for train, test in kf.split(x):\n",
    "    x_train, x_test, y_train, y_test = x[train],x[test],y[train],y[test]\n",
    "    \n",
    "    count_word_on_class, count_word, word_class = count_word_in_class(x_train,y_train)\n",
    "    count_class = count_class_in_doc(y_train)\n",
    "    kelaz = list(count_class.keys())\n",
    "    y_pred = []\n",
    "    for i in range(0,len(x_test)):\n",
    "        prob_kelas = {}\n",
    "        for j in count_class.keys():\n",
    "            prob_c = 1\n",
    "            x_split = x_test[i].split()\n",
    "            for k in x_split:\n",
    "                tag = k+str(',')+str(j)\n",
    "                prob_c += math.log(hitung_prob(count_word_on_class.get(tag,0),word_class.get(j),len(count_word.keys())))\n",
    "            nama = str(i)+','+str(j)\n",
    "            prob_kelas[nama] = prob_c\n",
    "        y_pred.append(kelaz[np.argmax(list(prob_kelas.values()))])\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "print(\"Mean Acc of\",folds,\"Fold:\",np.mean(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
